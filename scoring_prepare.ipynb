{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n",
      "Config(device='cuda',\n",
      "       worker_id=0,\n",
      "       worker_total=20,\n",
      "       dry_run=False,\n",
      "       debug=False,\n",
      "       output_dir='/raid/pdpl/trak/grads/',\n",
      "       save_dir='/raid/pdpl/trak/trak_results/',\n",
      "       write_chunks=1000,\n",
      "       seed=42,\n",
      "       proj_dim=2048,\n",
      "       num_contrastive_samples=50000,\n",
      "       datasets={'commonpool': DatasetConfig(uri='/datasets/datacomp/shards/{00000000..00001287}.tar',\n",
      "                                             uris=None,\n",
      "                                             size=None,\n",
      "                                             num_workers=16,\n",
      "                                             num_samples=10367394),\n",
      "                 'fairvision/AMD': DatasetConfig(uri='/datasets/fairvision/AMD/shards/amd-train-{000000..000005}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 num_samples=6000),\n",
      "                 'fairvision/DR': DatasetConfig(uri='/datasets/fairvision/DR/shards/dr-train-{000000..000005}.tar',\n",
      "                                                uris=None,\n",
      "                                                size=None,\n",
      "                                                num_workers=16,\n",
      "                                                num_samples=6000),\n",
      "                 'fairvision/Glaucoma': DatasetConfig(uri='/datasets/fairvision/Glaucoma/shards/glaucoma-train-{000000..000005}.tar',\n",
      "                                                      uris=None,\n",
      "                                                      size=None,\n",
      "                                                      num_workers=16,\n",
      "                                                      num_samples=6000),\n",
      "                 'fitzpatrick17k': DatasetConfig(uri='/datasets/fitzpatrick17k/shards/fitzpatrick17k-train-{000000..000012}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 num_samples=12858),\n",
      "                 'vtab/pcam': DatasetConfig(uri='/datasets/pcam/shards/pcam-train-{000000..000262}.tar',\n",
      "                                            uris=None,\n",
      "                                            size=None,\n",
      "                                            num_workers=16,\n",
      "                                            num_samples=262144)},\n",
      "       encoders=[EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_0',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v0/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=0),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_1',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v1/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=1),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_2',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v2/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=2)])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAK:Using ChunkedCudaProjector with2 chunks of sizes[125979393, 25297920].\n",
      "INFO:STORE:Existing model IDs in /raid/pdpl/trak/trak_results: [0, 1, 2]\n",
      "INFO:STORE:No model IDs in /raid/pdpl/trak/trak_results have been finalized.\n",
      "INFO:STORE:No existing TRAK scores in /raid/pdpl/trak/trak_results.\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "from config import Config\n",
    "from model import Model\n",
    "from trak import TRAKer\n",
    "\n",
    "cfg = Config()\n",
    "# cfg.device=\"cpu\"\n",
    "pprint(cfg)\n",
    "encoder_cfg = cfg.encoders[0]\n",
    "\n",
    "input_path = str(\n",
    "    Path(cfg.output_dir) / encoder_cfg.name / encoder_cfg.ood_dataset_name\n",
    ")\n",
    "dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "train_set_size = dataset.count_rows()\n",
    "model = Model(encoder_cfg, \"cpu\")\n",
    "model, _, _, _ = model.create_model_and_transforms()\n",
    "traker = TRAKer(\n",
    "    save_dir=cfg.save_dir,\n",
    "    model=model,\n",
    "    task=\"clip\",\n",
    "    train_set_size=train_set_size,\n",
    "    device=cfg.device,\n",
    "    proj_dim=cfg.proj_dim,\n",
    "    use_half_precision=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing blocks: 100%|██████████| 349/349 [10:55<00:00,  1.88s/it]<?, ?it/s]\n",
      "Processing blocks: 100%|██████████| 349/349 [12:01<00:00,  2.07s/it]<50:10, 1505.41s/it]\n",
      "Processing blocks: 100%|██████████| 349/349 [00:40<00:00,  8.67it/s]<30:03, 1803.31s/it]\n",
      "Finalizing features for all model IDs..: 100%|██████████| 3/3 [1:24:57<00:00, 1699.22s/it]\n"
     ]
    }
   ],
   "source": [
    "traker.finalize_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.progress import BarColumn, Progress, TextColumn, TimeElapsedColumn\n",
    "\n",
    "console = Console()\n",
    "\n",
    "for c in cfg.encoders[:2]:\n",
    "    console.rule(f\"[bold red]Processing encoder {c.name}\")\n",
    "\n",
    "    with Progress(\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        BarColumn(),\n",
    "        TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n",
    "        TimeElapsedColumn(),\n",
    "        # TimeRemainingColumn(),\n",
    "        console=console,\n",
    "    ) as progress:\n",
    "        # Create task for each operation\n",
    "        checkpoint_task = progress.add_task(\"Loading checkpoint...\", total=1)\n",
    "        traker_task = progress.add_task(\n",
    "            \"Loading checkpoint into TRAKer...\", total=1, visible=False\n",
    "        )\n",
    "        path_task = progress.add_task(\n",
    "            \"Setting up input path...\", total=1, visible=False\n",
    "        )\n",
    "        dataset_task = progress.add_task(\n",
    "            \"Loading dataset...\", total=1, visible=False\n",
    "        )\n",
    "        table_task = progress.add_task(\n",
    "            \"Converting to table...\", total=1, visible=False\n",
    "        )\n",
    "        sort_task = progress.add_task(\n",
    "            \"Sorting by uid...\", total=1, visible=False\n",
    "        )\n",
    "        grads_task = progress.add_task(\n",
    "            \"Stacking gradients...\", total=1, visible=False\n",
    "        )\n",
    "        loss_grads_task = progress.add_task(\n",
    "            \"Stacking loss gradients...\", total=1, visible=False\n",
    "        )\n",
    "        store_grads_task = progress.add_task(\n",
    "            \"Storing gradients...\", total=1, visible=False\n",
    "        )\n",
    "        store_loss_task = progress.add_task(\n",
    "            \"Storing loss gradients...\", total=1, visible=False\n",
    "        )\n",
    "        flag_task = progress.add_task(\n",
    "            \"Setting featurization flag...\", total=1, visible=False\n",
    "        )\n",
    "        meta_task = progress.add_task(\n",
    "            \"Serializing metadata...\", total=1, visible=False\n",
    "        )\n",
    "\n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(c.path, map_location=\"cpu\")\n",
    "        progress.update(checkpoint_task, advance=1)\n",
    "\n",
    "        # Load into TRAKer\n",
    "        progress.update(traker_task, visible=True)\n",
    "        traker.load_checkpoint(checkpoint, c.model_id)\n",
    "        progress.update(traker_task, advance=1)\n",
    "\n",
    "        # Setup input path\n",
    "        progress.update(path_task, visible=True)\n",
    "        input_path = str(Path(cfg.output_dir) / c.name / c.ood_dataset_name)\n",
    "        progress.update(path_task, advance=1)\n",
    "\n",
    "        # Load dataset\n",
    "        progress.update(dataset_task, visible=True)\n",
    "        dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "        progress.update(dataset_task, advance=1)\n",
    "\n",
    "        # Convert to table\n",
    "        progress.update(table_task, visible=True)\n",
    "        table = dataset.to_table(columns=[\"uid\", \"grads\", \"loss_grads\"])\n",
    "        progress.update(table_task, advance=1)\n",
    "\n",
    "        # Sorting by uid\n",
    "        progress.update(sort_task, visible=True)\n",
    "        table = table.sort_by(\"uid\")\n",
    "        progress.update(sort_task, advance=1)\n",
    "\n",
    "        # Stack gradients\n",
    "        progress.update(sort_task, visible=True)\n",
    "        grads = np.stack(table[\"grads\"].to_numpy())\n",
    "        progress.update(grads_task, advance=1)\n",
    "\n",
    "        # Stack loss gradients\n",
    "        progress.update(loss_grads_task, visible=True)\n",
    "        loss_grads = np.stack(table[\"loss_grads\"].to_numpy())\n",
    "        progress.update(loss_grads_task, advance=1)\n",
    "\n",
    "        # Store gradients\n",
    "        progress.update(store_grads_task, visible=True)\n",
    "        traker.saver.current_store[\"grads\"][:] = grads\n",
    "        progress.update(store_grads_task, advance=1)\n",
    "\n",
    "        # Store loss gradients\n",
    "        progress.update(store_loss_task, visible=True)\n",
    "        traker.saver.current_store[\"out_to_loss\"][:] = loss_grads[\n",
    "            :, np.newaxis\n",
    "        ]\n",
    "        progress.update(store_loss_task, advance=1)\n",
    "\n",
    "        # Set featurization flag\n",
    "        progress.update(flag_task, visible=True)\n",
    "        traker.saver.current_store[\"is_featurized\"][:] = 1\n",
    "        progress.update(flag_task, advance=1)\n",
    "\n",
    "        # Serialize metadata\n",
    "        progress.update(meta_task, visible=True)\n",
    "        traker.saver.serialize_current_model_id_metadata()\n",
    "        progress.update(meta_task, advance=1)\n",
    "\n",
    "    console.print(f\"[bold green]✓ Finished processing encoder {c.name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
