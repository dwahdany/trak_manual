{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now need to read the grads back into the proper TRAKer and continue\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "from config import Config\n",
    "from model import Model\n",
    "from trak import TRAKer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(device='cuda',\n",
      "       worker_id=0,\n",
      "       worker_total=20,\n",
      "       dry_run=False,\n",
      "       debug=False,\n",
      "       output_dir='/raid/pdpl/trak/grads/',\n",
      "       save_dir='/raid/pdpl/trak/trak_results/',\n",
      "       write_chunks=1000,\n",
      "       seed=42,\n",
      "       proj_dim=2048,\n",
      "       num_contrastive_samples=50000,\n",
      "       datasets={'commonpool': DatasetConfig(uri='/datasets/datacomp/shards/{00000000..00001287}.tar',\n",
      "                                             uris=None,\n",
      "                                             size=None,\n",
      "                                             num_workers=16,\n",
      "                                             num_samples=10367394),\n",
      "                 'fairvision/AMD': DatasetConfig(uri='/datasets/fairvision/AMD/shards/amd-train-{000000..000005}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 num_samples=6000),\n",
      "                 'fairvision/DR': DatasetConfig(uri='/datasets/fairvision/DR/shards/dr-train-{000000..000005}.tar',\n",
      "                                                uris=None,\n",
      "                                                size=None,\n",
      "                                                num_workers=16,\n",
      "                                                num_samples=6000),\n",
      "                 'fairvision/Glaucoma': DatasetConfig(uri='/datasets/fairvision/Glaucoma/shards/glaucoma-train-{000000..000005}.tar',\n",
      "                                                      uris=None,\n",
      "                                                      size=None,\n",
      "                                                      num_workers=16,\n",
      "                                                      num_samples=6000),\n",
      "                 'fitzpatrick17k': DatasetConfig(uri='/datasets/fitzpatrick17k/shards/fitzpatrick17k-train-{000000..000012}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 num_samples=12858),\n",
      "                 'vtab/pcam': DatasetConfig(uri='/datasets/pcam/shards/pcam-train-{000000..000262}.tar',\n",
      "                                            uris=None,\n",
      "                                            size=None,\n",
      "                                            num_workers=16,\n",
      "                                            num_samples=262144)},\n",
      "       encoders=[EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_0',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v0/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=0),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_1',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v1/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=1),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_2',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v2/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=2)])\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "# cfg.device=\"cpu\"\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cfg = cfg.encoders[2]\n",
    "from pathlib import Path\n",
    "\n",
    "input_path = str(\n",
    "    Path(cfg.output_dir) / encoder_cfg.name / encoder_cfg.ood_dataset_name\n",
    ")\n",
    "dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "train_set_size = dataset.count_rows()\n",
    "print(f\"Train set size: {train_set_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the uid column from the dataset\n",
    "uids = dataset.to_table(columns=[\"uid\"]).to_pandas()\n",
    "\n",
    "# Get unique file indices from uids\n",
    "file_indices = uids[\"uid\"].str.split(\"_\").str[0].unique()\n",
    "print(f\"UIDs are from files: {sorted(file_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(encoder_cfg, \"cpu\")\n",
    "model, _, _, _ = model.create_model_and_transforms()\n",
    "traker = TRAKer(\n",
    "    save_dir=cfg.save_dir,\n",
    "    model=model,\n",
    "    task=\"clip\",\n",
    "    train_set_size=train_set_size,\n",
    "    device=cfg.device,\n",
    "    proj_dim=cfg.proj_dim,\n",
    "    use_half_precision=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traker.saver.load_current_store(encoder_cfg.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "\n",
    "grads = traker.saver.current_store[\"grads\"]\n",
    "proj_dim = grads.shape[1]\n",
    "# result = ch.zeros(proj_dim, proj_dim, dtype=ch.float16, device=\"cuda\")\n",
    "blocks = ch.split(ch.as_tensor(grads), split_size_or_sections=20_000, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx = traker.score_computer.get_xtx(ch.as_tensor(grads)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg = 0.0  # Default regularization term\n",
    "dtype = ch.float16  # Using float16 as default\n",
    "CUDA_MAX_DIM_SIZE = 100_000\n",
    "grads = ch.as_tensor(traker.saver.current_store[\"grads\"])\n",
    "blocks = ch.split(grads, split_size_or_sections=CUDA_MAX_DIM_SIZE, dim=0)\n",
    "xtx_reg = xtx + lambda_reg * torch.eye(\n",
    "    xtx.size(dim=0), device=xtx.device, dtype=xtx.dtype\n",
    ")\n",
    "xtx_inv = ch.linalg.inv(xtx_reg.to(ch.float32))\n",
    "xtx_inv /= xtx_inv.abs().mean()\n",
    "\n",
    "xtx_inv = xtx_inv.to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ch.empty(grads.shape[0], xtx_inv.shape[1], dtype=dtype, device=\"cpu\")\n",
    "\n",
    "# for i, block in enumerate(tqdm(blocks, desc=\"Computing X^TX inverse\")):\n",
    "#     start = i * CUDA_MAX_DIM_SIZE\n",
    "#     end = min(grads.shape[0], (i + 1) * CUDA_MAX_DIM_SIZE)\n",
    "#     result[start:end] = block @ xtx_inv\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_jax = jnp.array(grads, device=jax.devices(\"cpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx_inv_jax = jnp.array(xtx_inv, device=jax.devices(\"cpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtx_inv_jax = process_large_grads(grads_jax, xtx_inv_jax, CUDA_MAX_DIM_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find factors of grads_jax.shape[0]\n",
    "n = grads_jax.shape[0]\n",
    "factors = [i for i in range(1, n + 1) if n % i == 0]\n",
    "smallest_factor_over_100 = next(f for f in sorted(factors) if f > 100)\n",
    "print(f\"Smallest factor of {n} over 100: {smallest_factor_over_100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_blocks = jnp.split(grads_jax, smallest_factor_over_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx_inv_gpu = jax.device_put(xtx_inv_jax, jax.devices(\"cuda\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx_inv_blocks = [\n",
    "    jax.device_get(jax.device_put(block, jax.devices(\"cuda\")[0]) @ xtx_inv_gpu)\n",
    "    for block in tqdm(grads_blocks)\n",
    "]\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    xtx_inv_jax = jnp.concatenate(xtx_inv_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traker.saver.current_store[\"features\"][:] = ch.as_tensor(\n",
    "    np.asarray(xtx_inv_jax), device=\"cpu\"\n",
    ")\n",
    "traker.saver.model_ids[encoder_cfg.model_id][\"is_finalized\"] = 1\n",
    "traker.saver.serialize_current_model_id_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traker.finalize_features(model_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from rich.console import Console\n",
    "from rich.progress import BarColumn, Progress, TextColumn, TimeElapsedColumn\n",
    "\n",
    "console = Console()\n",
    "\n",
    "for c in cfg.encoders[2:]:\n",
    "    console.rule(f\"[bold red]Processing encoder {c.name}\")\n",
    "\n",
    "    with Progress(\n",
    "        TextColumn(\"[progress.description]{task.description}\"),\n",
    "        BarColumn(),\n",
    "        TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n",
    "        TimeElapsedColumn(),\n",
    "        # TimeRemainingColumn(),\n",
    "        console=console,\n",
    "    ) as progress:\n",
    "        # Create task for each operation\n",
    "        checkpoint_task = progress.add_task(\"Loading checkpoint...\", total=1)\n",
    "        traker_task = progress.add_task(\n",
    "            \"Loading checkpoint into TRAKer...\", total=1, visible=False\n",
    "        )\n",
    "        path_task = progress.add_task(\n",
    "            \"Setting up input path...\", total=1, visible=False\n",
    "        )\n",
    "        dataset_task = progress.add_task(\n",
    "            \"Loading dataset...\", total=1, visible=False\n",
    "        )\n",
    "        table_task = progress.add_task(\n",
    "            \"Converting to table...\", total=1, visible=False\n",
    "        )\n",
    "        sort_task = progress.add_task(\n",
    "            \"Sorting by uid...\", total=1, visible=False\n",
    "        )\n",
    "        grads_task = progress.add_task(\n",
    "            \"Stacking gradients...\", total=1, visible=False\n",
    "        )\n",
    "        loss_grads_task = progress.add_task(\n",
    "            \"Stacking loss gradients...\", total=1, visible=False\n",
    "        )\n",
    "        store_grads_task = progress.add_task(\n",
    "            \"Storing gradients...\", total=1, visible=False\n",
    "        )\n",
    "        store_loss_task = progress.add_task(\n",
    "            \"Storing loss gradients...\", total=1, visible=False\n",
    "        )\n",
    "        flag_task = progress.add_task(\n",
    "            \"Setting featurization flag...\", total=1, visible=False\n",
    "        )\n",
    "        meta_task = progress.add_task(\n",
    "            \"Serializing metadata...\", total=1, visible=False\n",
    "        )\n",
    "\n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(c.path, map_location=\"cpu\")\n",
    "        progress.update(checkpoint_task, advance=1)\n",
    "\n",
    "        # Load into TRAKer\n",
    "        progress.update(traker_task, visible=True)\n",
    "        traker.load_checkpoint(checkpoint, c.model_id)\n",
    "        progress.update(traker_task, advance=1)\n",
    "\n",
    "        # Setup input path\n",
    "        progress.update(path_task, visible=True)\n",
    "        input_path = str(Path(cfg.output_dir) / c.name / c.ood_dataset_name)\n",
    "        progress.update(path_task, advance=1)\n",
    "\n",
    "        # Load dataset\n",
    "        progress.update(dataset_task, visible=True)\n",
    "        dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "        progress.update(dataset_task, advance=1)\n",
    "\n",
    "        # Convert to table\n",
    "        progress.update(table_task, visible=True)\n",
    "        table = dataset.to_table(columns=[\"uid\", \"grads\", \"loss_grads\"])\n",
    "        progress.update(table_task, advance=1)\n",
    "\n",
    "        # Sorting by uid\n",
    "        progress.update(sort_task, visible=True)\n",
    "        table = table.sort_by(\"uid\")\n",
    "        progress.update(sort_task, advance=1)\n",
    "\n",
    "        # Stack gradients\n",
    "        progress.update(sort_task, visible=True)\n",
    "        grads = np.stack(table[\"grads\"].to_numpy())\n",
    "        progress.update(grads_task, advance=1)\n",
    "\n",
    "        # Stack loss gradients\n",
    "        progress.update(loss_grads_task, visible=True)\n",
    "        loss_grads = np.stack(table[\"loss_grads\"].to_numpy())\n",
    "        progress.update(loss_grads_task, advance=1)\n",
    "\n",
    "        # Store gradients\n",
    "        progress.update(store_grads_task, visible=True)\n",
    "        traker.saver.current_store[\"grads\"][:] = grads\n",
    "        progress.update(store_grads_task, advance=1)\n",
    "\n",
    "        # Store loss gradients\n",
    "        progress.update(store_loss_task, visible=True)\n",
    "        traker.saver.current_store[\"out_to_loss\"][:] = loss_grads[\n",
    "            :, np.newaxis\n",
    "        ]\n",
    "        progress.update(store_loss_task, advance=1)\n",
    "\n",
    "        # Set featurization flag\n",
    "        progress.update(flag_task, visible=True)\n",
    "        traker.saver.current_store[\"is_featurized\"][:] = 1\n",
    "        progress.update(flag_task, advance=1)\n",
    "\n",
    "        # Serialize metadata\n",
    "        progress.update(meta_task, visible=True)\n",
    "        traker.saver.serialize_current_model_id_metadata()\n",
    "        progress.update(meta_task, advance=1)\n",
    "\n",
    "    console.print(f\"[bold green]âœ“ Finished processing encoder {c.name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
