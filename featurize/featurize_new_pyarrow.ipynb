{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=3\n",
      "Config(device='cuda',\n",
      "       worker_id=0,\n",
      "       worker_total=20,\n",
      "       dry_run=False,\n",
      "       debug=False,\n",
      "       output_dir='/raid/pdpl/trak/grads/',\n",
      "       save_dir='/raid/pdpl/trak/trak_results/',\n",
      "       write_chunks=1000,\n",
      "       seed=42,\n",
      "       proj_dim=2048,\n",
      "       num_contrastive_samples=50000,\n",
      "       datasets={'Food101': DatasetConfig(uri='/datasets/food101/shards/food101-train-{000000..000075}.tar',\n",
      "                                          uris=None,\n",
      "                                          size=None,\n",
      "                                          num_workers=16,\n",
      "                                          splittable=True,\n",
      "                                          custom=True),\n",
      "                 'commonpool': DatasetConfig(uri='/datasets/datacomp/shards/{00000000..00001287}.tar',\n",
      "                                             uris=None,\n",
      "                                             size=None,\n",
      "                                             num_workers=16,\n",
      "                                             splittable=True,\n",
      "                                             custom=False),\n",
      "                 'fairvision/AMD': DatasetConfig(uri='/datasets/fairvision/AMD/shards/amd-train-{000000..000005}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 splittable=True,\n",
      "                                                 custom=True),\n",
      "                 'fairvision/DR': DatasetConfig(uri='/datasets/fairvision/DR/shards/dr-train-{000000..000005}.tar',\n",
      "                                                uris=None,\n",
      "                                                size=None,\n",
      "                                                num_workers=16,\n",
      "                                                splittable=True,\n",
      "                                                custom=True),\n",
      "                 'fairvision/Glaucoma': DatasetConfig(uri='/datasets/fairvision/Glaucoma/shards/glaucoma-train-{000000..000005}.tar',\n",
      "                                                      uris=None,\n",
      "                                                      size=None,\n",
      "                                                      num_workers=16,\n",
      "                                                      splittable=True,\n",
      "                                                      custom=True),\n",
      "                 'fitzpatrick17k': DatasetConfig(uri='/datasets/fitzpatrick17k/shards/fitzpatrick17k-train-{000000..000012}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 splittable=True,\n",
      "                                                 custom=True),\n",
      "                 'pcam': DatasetConfig(uri='/datasets/pcam/shards/pcam-train-{000000..000262}.tar',\n",
      "                                       uris=None,\n",
      "                                       size=None,\n",
      "                                       num_workers=16,\n",
      "                                       splittable=True,\n",
      "                                       custom=True)},\n",
      "       encoders=[EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_0',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v0/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               target_datasets=['fairvision/AMD',\n",
      "                                                'fairvision/Glaucoma',\n",
      "                                                'fairvision/DR',\n",
      "                                                'fitzpatrick17k',\n",
      "                                                'Food101',\n",
      "                                                'pcam'],\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=0),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_1',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v1/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               target_datasets=['fairvision/AMD',\n",
      "                                                'fairvision/Glaucoma',\n",
      "                                                'fairvision/DR',\n",
      "                                                'fitzpatrick17k',\n",
      "                                                'Food101',\n",
      "                                                'pcam'],\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=1),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_2',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v2/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               target_datasets=['fairvision/AMD',\n",
      "                                                'fairvision/Glaucoma',\n",
      "                                                'fairvision/DR',\n",
      "                                                'fitzpatrick17k',\n",
      "                                                'Food101',\n",
      "                                                'pcam'],\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=2)])\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=3\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "import pyarrow.dataset as ds\n",
    "\n",
    "from config import Config\n",
    "\n",
    "cfg = Config()\n",
    "# cfg.device=\"cpu\"\n",
    "pprint(cfg)\n",
    "encoder_cfg = cfg.encoders[0]\n",
    "\n",
    "input_path = str(\n",
    "    Path(cfg.output_dir) / encoder_cfg.name / encoder_cfg.ood_dataset_name\n",
    ")\n",
    "dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "train_set_size = dataset.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cb958d2adf4d5e8a8f0f0764bf5afe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112378/130825196.py:9: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  for batch in tqdm(scanner.to_batches(), total=train_set_size // batch_size):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm.rich import tqdm\n",
    "\n",
    "batch_size = 16384\n",
    "scanner = dataset.scanner(columns=[\"grads\", \"uid\"], batch_size=batch_size)\n",
    "batches = scanner.to_batches()\n",
    "grads_list = []\n",
    "uids_list = []\n",
    "for batch in tqdm(scanner.to_batches(), total=train_set_size // batch_size):\n",
    "    grads_list.extend(batch.column(\"grads\").to_numpy(zero_copy_only=False))\n",
    "    uids_list.extend(batch.column(\"uid\").to_numpy(zero_copy_only=False))\n",
    "g = np.stack(grads_list)\n",
    "uids = np.stack(uids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort g and uids arrays by uids\n",
    "sort_indices = np.argsort(uids)\n",
    "g = g[sort_indices]\n",
    "uids = uids[sort_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "def get_xtx(grads: Tensor, batch_size=20_000) -> Tensor:\n",
    "    proj_dim = grads.shape[1]\n",
    "    result = ch.zeros(proj_dim, proj_dim, dtype=grads.dtype, device=\"cuda\")\n",
    "    blocks = ch.split(grads, split_size_or_sections=batch_size, dim=0)\n",
    "\n",
    "    for block in tqdm(blocks):\n",
    "        result += block.T.to(\"cuda\") @ block.to(\"cuda\")\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56e5d1a748e49f8822ce3660b8600cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112378/1931852164.py:10: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  for block in tqdm(blocks):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xtx = get_xtx(ch.tensor(g, device=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_x_xtx_inv(\n",
    "    grads: Tensor, xtx: Tensor, lambda_reg=0.0, batch_size=20_000\n",
    ") -> Tensor:\n",
    "    xtx_reg = xtx + lambda_reg * ch.eye(\n",
    "        xtx.size(dim=0), device=xtx.device, dtype=xtx.dtype\n",
    "    )\n",
    "    xtx_inv = ch.linalg.inv(xtx_reg.to(ch.float32))\n",
    "\n",
    "    # center X^TX inverse a bit to avoid numerical issues when going to float16\n",
    "    xtx_inv /= xtx_inv.abs().mean()\n",
    "    xtx_inv = xtx_inv.to(grads.dtype)\n",
    "\n",
    "    grads_blocks = ch.split(grads, split_size_or_sections=batch_size, dim=0)\n",
    "\n",
    "    # Move xtx_inv to GPU once before the loop\n",
    "    xtx_inv_gpu = xtx_inv.cuda()\n",
    "\n",
    "    # Process blocks on GPU\n",
    "    result_blocks = []\n",
    "    for block in tqdm(grads_blocks, desc=\"Processing blocks\"):\n",
    "        # Move block to GPU, compute, then back to CPU\n",
    "        block_gpu = block.cuda()\n",
    "        result_gpu = block_gpu @ xtx_inv_gpu\n",
    "        result_blocks.append(result_gpu.cpu())\n",
    "\n",
    "    # Concatenate results on CPU\n",
    "    result = ch.cat(result_blocks)\n",
    "\n",
    "    return result.to(dtype=grads.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80c84da6b8c4c6e9b425d474b1f7e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112378/1614473132.py:20: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  for block in tqdm(grads_blocks, desc=\"Processing blocks\"):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_xtx_inv = get_x_xtx_inv(ch.tensor(g, device=\"cpu\"), xtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = x_xtx_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91fd0f49fb5b41c8b61bcbea69a95054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_112378/4260970767.py:12: TqdmExperimentalWarning: rich is experimental/alpha\n",
      "  for batch in tqdm(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get target features\n",
    "target = \"fairvision/amd\"\n",
    "input_path = str(Path(cfg.output_dir) / encoder_cfg.name / target)\n",
    "dataset_target = ds.dataset(input_path, format=\"parquet\")\n",
    "batch_size = 16384\n",
    "scanner = dataset_target.scanner(\n",
    "    columns=[\"grads\", \"uid\"], batch_size=batch_size\n",
    ")\n",
    "batches = scanner.to_batches()\n",
    "grads_list = []\n",
    "uids_list = []\n",
    "for batch in tqdm(\n",
    "    scanner.to_batches(), total=dataset_target.count_rows() // batch_size\n",
    "):\n",
    "    grads_list.extend(batch.column(\"grads\").to_numpy(zero_copy_only=False))\n",
    "    uids_list.extend(batch.column(\"uid\").to_numpy(zero_copy_only=False))\n",
    "g_target = np.stack(grads_list)\n",
    "uids_target = np.stack(uids_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trak.utils import get_matrix_mult_blockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_matrix_mult_blockwise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m full_scores \u001b[38;5;241m=\u001b[39m \u001b[43mget_matrix_mult_blockwise\u001b[49m(\n\u001b[1;32m      2\u001b[0m     features, ch\u001b[38;5;241m.\u001b[39mtensor(g_target, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m), ch\u001b[38;5;241m.\u001b[39mfloat16, bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m\n\u001b[1;32m      3\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_matrix_mult_blockwise' is not defined"
     ]
    }
   ],
   "source": [
    "full_scores = get_matrix_mult_blockwise(\n",
    "    features, ch.tensor(g_target, device=\"cpu\"), ch.float16, bs=2048\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
