{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we now need to read the grads back into the proper TRAKer and continue\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pyarrow.dataset as ds\n",
    "import torch\n",
    "from config import Config\n",
    "from model import Model\n",
    "from trak import TRAKer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config(device='cuda',\n",
      "       worker_id=0,\n",
      "       worker_total=20,\n",
      "       dry_run=False,\n",
      "       debug=False,\n",
      "       output_dir='/raid/pdpl/trak/grads/',\n",
      "       save_dir='/raid/pdpl/trak/trak_results/',\n",
      "       write_chunks=1000,\n",
      "       seed=42,\n",
      "       proj_dim=2048,\n",
      "       num_contrastive_samples=50000,\n",
      "       datasets={'commonpool': DatasetConfig(uri='/datasets/datacomp/shards/{00000000..00001287}.tar',\n",
      "                                             uris=None,\n",
      "                                             size=None,\n",
      "                                             num_workers=16,\n",
      "                                             num_samples=10367394),\n",
      "                 'fairvision/AMD': DatasetConfig(uri='/datasets/fairvision/AMD/shards/amd-train-{000000..000005}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 num_samples=6000),\n",
      "                 'fairvision/DR': DatasetConfig(uri='/datasets/fairvision/DR/shards/dr-train-{000000..000005}.tar',\n",
      "                                                uris=None,\n",
      "                                                size=None,\n",
      "                                                num_workers=16,\n",
      "                                                num_samples=6000),\n",
      "                 'fairvision/Glaucoma': DatasetConfig(uri='/datasets/fairvision/Glaucoma/shards/glaucoma-train-{000000..000005}.tar',\n",
      "                                                      uris=None,\n",
      "                                                      size=None,\n",
      "                                                      num_workers=16,\n",
      "                                                      num_samples=6000),\n",
      "                 'fitzpatrick17k': DatasetConfig(uri='/datasets/fitzpatrick17k/shards/fitzpatrick17k-train-{000000..000012}.tar',\n",
      "                                                 uris=None,\n",
      "                                                 size=None,\n",
      "                                                 num_workers=16,\n",
      "                                                 num_samples=12858),\n",
      "                 'vtab/pcam': DatasetConfig(uri='/datasets/pcam/shards/pcam-train-{000000..000262}.tar',\n",
      "                                            uris=None,\n",
      "                                            size=None,\n",
      "                                            num_workers=16,\n",
      "                                            num_samples=262144)},\n",
      "       encoders=[EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_0',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v0/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=0),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_1',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v1/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=1),\n",
      "                 EncoderConfig(architecture='ViT-B-32',\n",
      "                               name='local_commonpool_s_s13m_b4k_2',\n",
      "                               path='/raid/pdpl/small_clip_checkpoints/raw/datacomp_v2/small_scale/checkpoints/epoch_5.pt',\n",
      "                               url=None,\n",
      "                               ood_dataset_name='commonpool',\n",
      "                               id_dataset_name=None,\n",
      "                               precision='pure_fp16',\n",
      "                               embedding_batch_size=2048,\n",
      "                               grad_batch_size=48,\n",
      "                               model_id=2)])\n"
     ]
    }
   ],
   "source": [
    "cfg = Config()\n",
    "# cfg.device=\"cpu\"\n",
    "pprint(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cfg = cfg.encoders[1]\n",
    "from pathlib import Path\n",
    "\n",
    "input_path = str(\n",
    "    Path(cfg.output_dir) / encoder_cfg.name / encoder_cfg.ood_dataset_name\n",
    ")\n",
    "dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "train_set_size = dataset.count_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:TRAK:Using ChunkedCudaProjector with2 chunks of sizes[125979393, 25297920].\n",
      "INFO:STORE:Existing model IDs in /raid/pdpl/trak/trak_results: [0, 1]\n",
      "INFO:STORE:Model IDs that have been finalized: [0]\n",
      "INFO:STORE:No existing TRAK scores in /raid/pdpl/trak/trak_results.\n"
     ]
    }
   ],
   "source": [
    "model = Model(encoder_cfg, \"cpu\")\n",
    "model, _, _, _ = model.create_model_and_transforms()\n",
    "traker = TRAKer(\n",
    "    save_dir=cfg.save_dir,\n",
    "    model=model,\n",
    "    task=\"clip\",\n",
    "    train_set_size=train_set_size,\n",
    "    device=cfg.device,\n",
    "    proj_dim=cfg.proj_dim,\n",
    "    use_half_precision=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "traker.saver.load_current_store(encoder_cfg.model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as ch\n",
    "\n",
    "grads = traker.saver.current_store[\"grads\"]\n",
    "proj_dim = grads.shape[1]\n",
    "# result = ch.zeros(proj_dim, proj_dim, dtype=ch.float16, device=\"cuda\")\n",
    "blocks = ch.split(ch.as_tensor(grads), split_size_or_sections=20_000, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx = traker.score_computer.get_xtx(ch.as_tensor(grads)).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_reg = 0.0  # Default regularization term\n",
    "dtype = ch.float16  # Using float16 as default\n",
    "CUDA_MAX_DIM_SIZE = 100_000\n",
    "grads = ch.as_tensor(traker.saver.current_store[\"grads\"])\n",
    "blocks = ch.split(grads, split_size_or_sections=CUDA_MAX_DIM_SIZE, dim=0)\n",
    "xtx_reg = xtx + lambda_reg * torch.eye(\n",
    "    xtx.size(dim=0), device=xtx.device, dtype=xtx.dtype\n",
    ")\n",
    "xtx_inv = ch.linalg.inv(xtx_reg.to(ch.float32))\n",
    "xtx_inv /= xtx_inv.abs().mean()\n",
    "\n",
    "xtx_inv = xtx_inv.to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = ch.empty(grads.shape[0], xtx_inv.shape[1], dtype=dtype, device=\"cpu\")\n",
    "\n",
    "# for i, block in enumerate(tqdm(blocks, desc=\"Computing X^TX inverse\")):\n",
    "#     start = i * CUDA_MAX_DIM_SIZE\n",
    "#     end = min(grads.shape[0], (i + 1) * CUDA_MAX_DIM_SIZE)\n",
    "#     result[start:end] = block @ xtx_inv\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_jax = jnp.array(grads, device=jax.devices(\"cpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx_inv_jax = jnp.array(xtx_inv, device=jax.devices(\"cpu\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtx_inv_jax = process_large_grads(grads_jax, xtx_inv_jax, CUDA_MAX_DIM_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest factor of 10367394 over 100: 349\n"
     ]
    }
   ],
   "source": [
    "# Find factors of grads_jax.shape[0]\n",
    "n = grads_jax.shape[0]\n",
    "factors = [i for i in range(1, n + 1) if n % i == 0]\n",
    "smallest_factor_over_100 = next(f for f in sorted(factors) if f > 100)\n",
    "print(f\"Smallest factor of {n} over 100: {smallest_factor_over_100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads_blocks = jnp.split(grads_jax, smallest_factor_over_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx_inv_gpu = jax.device_put(xtx_inv_jax, jax.devices(\"cuda\")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [00:28<00:00, 12.16it/s]\n"
     ]
    }
   ],
   "source": [
    "xtx_inv_blocks = [\n",
    "    jax.device_get(jax.device_put(block, jax.devices(\"cuda\")[0]) @ xtx_inv_gpu)\n",
    "    for block in tqdm(grads_blocks)\n",
    "]\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    xtx_inv_jax = jnp.concatenate(xtx_inv_blocks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2912542/1638888360.py:1: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "  traker.saver.current_store[\"features\"][:] = ch.as_tensor(\n"
     ]
    }
   ],
   "source": [
    "traker.saver.current_store[\"features\"][:] = ch.as_tensor(\n",
    "    np.asarray(xtx_inv_jax), device=\"cpu\"\n",
    ")\n",
    "traker.saver.model_ids[encoder_cfg.model_id][\"is_finalized\"] = 1\n",
    "traker.saver.serialize_current_model_id_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finalizing features for all model IDs..:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3df98985e44d59aca182e12aea24ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e5dd49f528047e6b832b2b61466374f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# traker.finalize_features(model_ids=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# from rich.console import Console\n",
    "# from rich.progress import BarColumn, Progress, TextColumn, TimeElapsedColumn\n",
    "\n",
    "# console = Console()\n",
    "\n",
    "# for c in cfg.encoders[2:]:\n",
    "#     console.rule(f\"[bold red]Processing encoder {c.name}\")\n",
    "\n",
    "#     with Progress(\n",
    "#         TextColumn(\"[progress.description]{task.description}\"),\n",
    "#         BarColumn(),\n",
    "#         TextColumn(\"[progress.percentage]{task.percentage:>3.0f}%\"),\n",
    "#         TimeElapsedColumn(),\n",
    "#         # TimeRemainingColumn(),\n",
    "#         console=console,\n",
    "#     ) as progress:\n",
    "#         # Create task for each operation\n",
    "#         checkpoint_task = progress.add_task(\"Loading checkpoint...\", total=1)\n",
    "#         traker_task = progress.add_task(\n",
    "#             \"Loading checkpoint into TRAKer...\", total=1, visible=False\n",
    "#         )\n",
    "#         path_task = progress.add_task(\n",
    "#             \"Setting up input path...\", total=1, visible=False\n",
    "#         )\n",
    "#         dataset_task = progress.add_task(\n",
    "#             \"Loading dataset...\", total=1, visible=False\n",
    "#         )\n",
    "#         table_task = progress.add_task(\n",
    "#             \"Converting to table...\", total=1, visible=False\n",
    "#         )\n",
    "#         grads_task = progress.add_task(\n",
    "#             \"Stacking gradients...\", total=1, visible=False\n",
    "#         )\n",
    "#         loss_grads_task = progress.add_task(\n",
    "#             \"Stacking loss gradients...\", total=1, visible=False\n",
    "#         )\n",
    "#         store_grads_task = progress.add_task(\n",
    "#             \"Storing gradients...\", total=1, visible=False\n",
    "#         )\n",
    "#         store_loss_task = progress.add_task(\n",
    "#             \"Storing loss gradients...\", total=1, visible=False\n",
    "#         )\n",
    "#         flag_task = progress.add_task(\n",
    "#             \"Setting featurization flag...\", total=1, visible=False\n",
    "#         )\n",
    "#         meta_task = progress.add_task(\n",
    "#             \"Serializing metadata...\", total=1, visible=False\n",
    "#         )\n",
    "\n",
    "#         # Load checkpoint\n",
    "#         checkpoint = torch.load(c.path, map_location=\"cpu\")\n",
    "#         progress.update(checkpoint_task, advance=1)\n",
    "\n",
    "#         # Load into TRAKer\n",
    "#         progress.update(traker_task, visible=True)\n",
    "#         traker.load_checkpoint(checkpoint, c.model_id)\n",
    "#         progress.update(traker_task, advance=1)\n",
    "\n",
    "#         # Setup input path\n",
    "#         progress.update(path_task, visible=True)\n",
    "#         input_path = str(Path(cfg.output_dir) / c.name / c.ood_dataset_name)\n",
    "#         progress.update(path_task, advance=1)\n",
    "\n",
    "#         # Load dataset\n",
    "#         progress.update(dataset_task, visible=True)\n",
    "#         dataset = ds.dataset(input_path, format=\"parquet\")\n",
    "#         progress.update(dataset_task, advance=1)\n",
    "\n",
    "#         # Convert to table\n",
    "#         progress.update(table_task, visible=True)\n",
    "#         table = dataset.to_table(columns=[\"grads\", \"loss_grads\"])\n",
    "#         progress.update(table_task, advance=1)\n",
    "\n",
    "#         # Stack gradients\n",
    "#         progress.update(grads_task, visible=True)\n",
    "#         grads = np.stack(table[\"grads\"].to_numpy())\n",
    "#         progress.update(grads_task, advance=1)\n",
    "\n",
    "#         # Stack loss gradients\n",
    "#         progress.update(loss_grads_task, visible=True)\n",
    "#         loss_grads = np.stack(table[\"loss_grads\"].to_numpy())\n",
    "#         progress.update(loss_grads_task, advance=1)\n",
    "\n",
    "#         # Store gradients\n",
    "#         progress.update(store_grads_task, visible=True)\n",
    "#         traker.saver.current_store[\"grads\"][:] = grads\n",
    "#         progress.update(store_grads_task, advance=1)\n",
    "\n",
    "#         # Store loss gradients\n",
    "#         progress.update(store_loss_task, visible=True)\n",
    "#         traker.saver.current_store[\"out_to_loss\"][:] = loss_grads[\n",
    "#             :, np.newaxis\n",
    "#         ]\n",
    "#         progress.update(store_loss_task, advance=1)\n",
    "\n",
    "#         # Set featurization flag\n",
    "#         progress.update(flag_task, visible=True)\n",
    "#         traker.saver.current_store[\"is_featurized\"][:] = 1\n",
    "#         progress.update(flag_task, advance=1)\n",
    "\n",
    "#         # Serialize metadata\n",
    "#         progress.update(meta_task, visible=True)\n",
    "#         traker.saver.serialize_current_model_id_metadata()\n",
    "#         progress.update(meta_task, advance=1)\n",
    "\n",
    "#     console.print(f\"[bold green]✓ Finished processing encoder {c.name}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
